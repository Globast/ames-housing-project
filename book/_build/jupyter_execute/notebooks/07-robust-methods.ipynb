{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc5e2f8",
   "metadata": {},
   "source": [
    "# Capítulo 7: Remedios y métodos robustos\n",
    "## Overview\n",
    "Se exploran **estimadores robustos** (p. ej., Huber/RLM, Quantile Regression) y/o **validación** (holdout/K-fold). Se compara la estabilidad de coeficientes y el desempeño predictivo frente a OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43fd87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando CSV: /workspaces/ames-housing-project/book/data/AmesHousing_codificada.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2768, 222)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Definir ruta de datos relativa al capítulo (ejecutado desde book/notebooks/)\n",
    "DATA_PATH = Path(\"../data/AmesHousing_codificada.csv\")\n",
    "assert DATA_PATH.is_file(), f\"No se encontró '{DATA_PATH}'\"\n",
    "print(\"Usando CSV:\", DATA_PATH.resolve())\n",
    "\n",
    "# Lectura canónica a reutilizar en el capítulo\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017f917",
   "metadata": {},
   "source": [
    "### 7.1 Correcciones para heterocedasticidad\n",
    "\n",
    "De acuerdo con el supuesto de homocedasticidad ([Ecuación 6.2.1](#ecuacion-621-varianza-errores)), la presencia de heterocedasticidad puede provocar que los errores estándar de los coeficientes estén subestimados, afectando los valores $t$ y las decisiones de significancia. Para corregir este problema, se utilizan los estimadores de varianza robusta **HC** (Heteroscedasticity-Consistent), que ajustan los errores estándar sin cambiar los coeficientes estimados. \n",
    "\n",
    "- **HC0**: Estimador original de White, básico y consistente frente a heterocedasticidad.  \n",
    "- **HC1**: Ajusta HC0 por los grados de libertad, corrigiendo ligeras subestimaciones.  \n",
    "- **HC2**: Considera los *leverage points* de cada observación, dando más peso a observaciones influyentes.  \n",
    "- **HC3**: Aproximación tipo *jackknife*, más conservadora y recomendada en muestras pequeñas por ofrecer errores estándar más cautelosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6767875c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msm\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m pd.set_option(\u001b[33m'\u001b[39m\u001b[33mdisplay.float_format\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[33m'\u001b[39m.format)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "data_modelo_base = pd.read_csv(DATA_PATH)\n",
    "\n",
    "data_modelo_base = data_modelo_base[['SalePrice_log', 'Overall Qual', 'Gr Liv Area', \n",
    "                                     'Garage Cars', 'Total Bsmt SF', '1st Flr SF', \n",
    "                                     'Full Bath', 'Year Built', 'Fireplaces', 'Lot Area']]\n",
    "X = data_modelo_base[['Overall Qual', 'Gr Liv Area', 'Garage Cars', 'Total Bsmt SF',\n",
    "                      '1st Flr SF', 'Full Bath', 'Year Built', 'Fireplaces', 'Lot Area']]\n",
    "y = data_modelo_base[['SalePrice_log']]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "modelo_base = sm.OLS(y, X).fit()\n",
    "\n",
    "resultados_HC0 = modelo_base.get_robustcov_results(cov_type='HC0')\n",
    "resultados_HC1 = modelo_base.get_robustcov_results(cov_type='HC1')\n",
    "resultados_HC2 = modelo_base.get_robustcov_results(cov_type='HC2')\n",
    "resultados_HC3 = modelo_base.get_robustcov_results(cov_type='HC3')\n",
    "\n",
    "def get_confint_df(result, var_names):\n",
    "    ci = result.conf_int()\n",
    "    if isinstance(ci, pd.DataFrame):\n",
    "        ci = ci.loc[var_names]\n",
    "    else:\n",
    "        ci = pd.DataFrame(ci, columns=[\"lower\", \"upper\"], index=var_names)\n",
    "    return ci\n",
    "\n",
    "variables = modelo_base.params.index\n",
    "\n",
    "se_df = pd.DataFrame({\n",
    "    \"OLS\": modelo_base.bse,\n",
    "    \"HC0\": resultados_HC0.bse,\n",
    "    \"HC1\": resultados_HC1.bse,\n",
    "    \"HC2\": resultados_HC2.bse,\n",
    "    \"HC3\": resultados_HC3.bse,\n",
    "})\n",
    "se_df.index.name = \"Variable\"\n",
    "\n",
    "ic_ols = get_confint_df(modelo_base, variables)\n",
    "ic_hc0 = get_confint_df(resultados_HC0, variables)\n",
    "ic_hc1 = get_confint_df(resultados_HC1, variables)\n",
    "ic_hc2 = get_confint_df(resultados_HC2, variables)\n",
    "ic_hc3 = get_confint_df(resultados_HC3, variables)\n",
    "\n",
    "ic_df = pd.DataFrame({\n",
    "    \"OLS_lower\": ic_ols.iloc[:,0],\n",
    "    \"OLS_upper\": ic_ols.iloc[:,1],\n",
    "    \"HC0_lower\": ic_hc0.iloc[:,0],\n",
    "    \"HC0_upper\": ic_hc0.iloc[:,1],\n",
    "    \"HC1_lower\": ic_hc1.iloc[:,0],\n",
    "    \"HC1_upper\": ic_hc1.iloc[:,1],\n",
    "    \"HC2_lower\": ic_hc2.iloc[:,0],\n",
    "    \"HC2_upper\": ic_hc2.iloc[:,1],\n",
    "    \"HC3_lower\": ic_hc3.iloc[:,0],\n",
    "    \"HC3_upper\": ic_hc3.iloc[:,1],\n",
    "})\n",
    "ic_df.index = variables\n",
    "ic_df.index.name = \"Variable\"\n",
    "\n",
    "display(se_df.style.format(\"{:.6f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e878864",
   "metadata": {},
   "source": [
    "**Tabla 7.1.1.** Errores estándar OLS vs. HC0-HC3.\n",
    "\n",
    "Se observa que los errores estándar aumentan ligeramente cuando se aplican las correcciones HC, especialmente para variables como `Overall Qual`, `Garage Cars` y `Full Bath`. Esto indica que los estimadores OLS originales podrían subestimar la variabilidad de los coeficientes si existe heterocedasticidad.\n",
    "\n",
    "Por ejemplo, el coeficiente de `Overall Qual` tiene un error estándar de 0.00333 bajo OLS clásico, que se incrementa a 0.00447 bajo HC3, la corrección más conservadora. De manera similar, `Garage Cars` pasa de 0.00530 a 0.00687.  \n",
    "\n",
    "Las variables con cambios mínimos en los errores estándar (como `Gr Liv Area` o `Lot Area`) sugieren que su variabilidad está poco afectada por heterocedasticidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de037326",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ic_df.style.format(\"{:.6f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b4a33",
   "metadata": {},
   "source": [
    "**Tabla 7.1.2.** Intervalos de confianza OLS vs. HC0-HC3.\n",
    "\n",
    "Se puede observar que los intervalos de confianza se ensanchan ligeramente cuando se aplican las correcciones HC, reflejando un aumento en la incertidumbre de los coeficientes. Por ejemplo, el coeficiente de `Overall Qual` tiene un intervalo de confianza de [0.095, 0.108] bajo OLS, que se amplía a [0.0929, 0.1104] con HC3. Lo mismo ocurre con `Garage Cars` y `Full Bath`, indicando que las inferencias de estos coeficientes son sensibles a la heterocedasticidad.\n",
    "\n",
    "En contraste, intervalos de confianza prácticamente inalterados, como los de `Gr Liv Area` o `Lot Area`, sugieren que la heterocedasticidad tiene poco efecto sobre la precisión de estos coeficientes.  \n",
    "\n",
    "En general, aplicar correcciones HC permite obtener intervalos de confianza más robustos, proporcionando inferencias más conservadoras y fiables cuando se sospecha heterocedasticidad.\n",
    "\n",
    "### 7.2 Modelos robustos con funciones Huber/Tukey\n",
    "\n",
    "Los **modelos de regresión robusta** son una extensión de la regresión lineal ordinaria diseñada para reducir la influencia de outliers o valores atípicos en la estimación de los coeficientes. Mientras que la regresión OLS pondera todos los residuales por igual, los modelos robustos asignan **menor peso a los residuales grandes**, permitiendo obtener estimaciones más confiables y estables.\n",
    "\n",
    "Existen diversas funciones de pérdida que determinan cómo se penalizan los residuales, donde cada una equilibra de distinta manera la eficiencia para valores centrales y la robustez frente a outliers extremos:\n",
    "\n",
    "- **Huber / TukeyHuberT()**:\n",
    "\n",
    "$$\n",
    "\\rho(r) = \n",
    "\\begin{cases} \n",
    "\\frac{1}{2} r^2 & \\text{si } |r| \\le \\delta \\\\[2mm]\n",
    "\\delta \\left(|r| - \\frac{1}{2}\\delta \\right) & \\text{si } |r| > \\delta\n",
    "\\end{cases}\n",
    "$$  \n",
    "**Ecuación 7.2.1.** Función de pérdida Huber.\n",
    "\n",
    "Protege contra outliers moderados manteniendo eficiencia para valores centrales.\n",
    "\n",
    "- **Tukey Biweight**:\n",
    "\n",
    "$$\n",
    "\\rho(r) = \n",
    "\\begin{cases}\n",
    "\\frac{c^2}{6} \\left[ 1 - \\left(1 - \\left(\\frac{r}{c}\\right)^2 \\right)^3 \\right] & \\text{si } |r| \\le c \\\\[1mm]\n",
    "\\frac{c^2}{6} & \\text{si } |r| > c\n",
    "\\end{cases}\n",
    "$$  \n",
    "**Ecuación 7.2.2.** Función de pérdida Tukey.\n",
    "\n",
    "Limita el impacto de observaciones lejanas sin eliminarlas completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "rlm_huber = sm.RLM(y, X, M=sm.robust.norms.HuberT()).fit()       # Función de pérdida Huber\n",
    "rlm_tukey = sm.RLM(y, X, M=sm.robust.norms.TukeyBiweight()).fit() # Función de pérdida Tukey Biweight\n",
    "\n",
    "rlm_df = pd.DataFrame({\n",
    "    'OLS': modelo_base.params,\n",
    "    'RLM_Huber': rlm_huber.params,\n",
    "    'RLM_Tukey': rlm_tukey.params\n",
    "})\n",
    "\n",
    "weights_df = pd.DataFrame({\n",
    "    'Huber_weights': rlm_huber.weights,\n",
    "    'Tukey_weights': rlm_tukey.weights\n",
    "})\n",
    "\n",
    "display(rlm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66b338",
   "metadata": {},
   "source": [
    "**Tabla 7.2.1.** Coeficientes OLS vs. RLM. *Valores en escala logarítmica.*\n",
    "\n",
    "Se observa que el intercepto (`const`) aumenta al usar modelos robustos, lo que refleja que los outliers tienden a sesgar hacia abajo la estimación en OLS. Por su parte, variables como `Overall Qual` y `Fireplaces` muestran coeficientes algo menores en modelos robustos, indicando que su efecto estaba ligeramente sobreestimado por la presencia de outliers. \n",
    "\n",
    "Para la mayoría de las demás variables (`Gr Liv Area`, `Garage Cars`, `Total Bsmt SF`, `Year Built`), las diferencias son pequeñas, lo que sugiere que los outliers no tienen un impacto fuerte en estas estimaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70559674",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(weights_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5af33",
   "metadata": {},
   "source": [
    "**Tabla 7.2.2.** Pesos outliers Huber vs. Tukey.\n",
    "\n",
    "La mayoría de los pesos son cercanos a 1 en ambos modelos robustos, lo que indica que la mayoría de las observaciones se ajusta bien al modelo y tiene plena influencia en la estimación de los coeficientes. \n",
    "\n",
    "Sin embargo, algunas observaciones presentan pesos menores, como la última fila, con Huber = 0.69 y Tukey = 0.68, lo que refleja que su residuo es relativamente grande y su efecto en el ajuste se atenúa.\n",
    "\n",
    "Además, es evidente que Tukey aplica un castigo más fuerte a residuales extremos.\n",
    "\n",
    "### 7.3 Bootstrap\n",
    "\n",
    "El **bootstrap** es un método de remuestreo que permite estimar la variabilidad de los coeficientes de un modelo sin asumir una distribución específica de los errores. Consiste en generar múltiples muestras con reemplazo a partir de los datos originales y recalcular los estimadores para cada réplica, obteniendo así una **distribución empírica** de los coeficientes, a partir de la cual se calculan el error estándar y los intervalos de confianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "B = 1000\n",
    "coef_boot = np.zeros((B, X.shape[1]))\n",
    "\n",
    "for i in range(B):\n",
    "    X_resample, y_resample = resample(X, y)\n",
    "    model_bs = sm.OLS(y_resample, X_resample).fit()\n",
    "    coef_boot[i, :] = model_bs.params\n",
    "\n",
    "coef_mean = coef_boot.mean(axis=0)        \n",
    "coef_se = coef_boot.std(axis=0)                     \n",
    "ic_lower = np.percentile(coef_boot, 2.5, axis=0)       \n",
    "ic_upper = np.percentile(coef_boot, 97.5, axis=0)  \n",
    "\n",
    "bootstrap_df = pd.DataFrame({\n",
    "    'Coef_mean': coef_mean,\n",
    "    'SE_bootstrap': coef_se,\n",
    "    'IC_2.5%': ic_lower,\n",
    "    'IC_97.5%': ic_upper\n",
    "}, index=X.columns)\n",
    "\n",
    "bootstrap_df.to_csv('bootstrap_df.csv', sep=\",\", index=False)\n",
    "\n",
    "bootstrap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe772f",
   "metadata": {},
   "source": [
    "**Tabla 7.3.1.** Resumen Bootstrap.\n",
    "\n",
    "Se observa que variables como `Overall Qual`, `Gr Liv Area`, `Garage Cars` y `Year Built` tienen coeficientes claramente distintos de cero, con intervalos de confianza estrechos y consistentes, lo que sugiere estimaciones robustas y estables. Por el contrario, `1st Flr SF` y `Full Bath` presentan intervalos que incluyen el cero, indicando que su efecto sobre la variable respuesta podría no ser significativo.\n",
    "\n",
    "### 7.4 OLS vs. HC3 vs. Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c623595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coef_ols = modelo_base.params         \n",
    "se_ols = modelo_base.bse               \n",
    "\n",
    "se_hc3 = resultados_HC3.bse            \n",
    "\n",
    "coef_boot_mean = bootstrap_df['Coef_mean']  \n",
    "se_boot = bootstrap_df['SE_bootstrap']  \n",
    "\n",
    "ic_ols = modelo_base.conf_int().iloc[:,1] - modelo_base.conf_int().iloc[:,0]\n",
    "\n",
    "ic_hc3 = resultados_HC3.conf_int()[:,1] - resultados_HC3.conf_int()[:,0]\n",
    "\n",
    "ic_boot = bootstrap_df['IC_97.5%'] - bootstrap_df['IC_2.5%']\n",
    "\n",
    "coef_df = comparative_df[['Coef_OLS', 'Coef_Bootstrap']]\n",
    "se_df = comparative_df[['SE_OLS', 'SE_HC3', 'SE_Bootstrap']]\n",
    "ic_df = comparative_df[['IC_width_OLS', 'IC_width_HC3', 'IC_width_Bootstrap']]\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db328a",
   "metadata": {},
   "source": [
    "**Tabla 7.4.1.** Coeficientes OLS vs. Bootstrap. *Valores en escala logarítmica.*\n",
    "\n",
    "Se observa que la estimación de los parámetros es muy estable frente al remuestreo, lo que sugiere que la muestra utilizada es suficientemente representativa y que los coeficientes no dependen excesivamente de observaciones individuales.\n",
    "\n",
    "En particular, las variables como `Overall Qual`, `Gr Liv Area` y `Fireplaces` muestran coeficientes positivos consistentes en ambos métodos, confirmando su relación directa con el precio de la vivienda. Por su parte, `Full Bath` mantiene un coeficiente ligeramente negativo, indicando que, controlando por las demás variables, su efecto es mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010d129",
   "metadata": {},
   "source": [
    "**Tabla 7.4.2.** Errores estándar OLS vs. HC3 vs. Bootstrap.<a id=\"tabla-742-se-ols-hc3-boot\"></a>\n",
    "\n",
    "Los errores estándar de OLS son generalmente menores que los obtenidos mediante HC3 o bootstrap, lo que sugiere que este modelo inicial podría subestimar la incertidumbre cuando hay heterocedasticidad presente o dependiendo de la muestra seleccionada.  \n",
    "\n",
    "El método HC3, diseñado para ser más conservador frente a heterocedasticidad y leverage points, produce errores estándar ligeramente mayores que OLS, especialmente para variables como `Overall Qual`, `Garage Cars` y `Full Bath`. El bootstrap refleja un patrón muy similar al de HC3, confirmando la estabilidad de las estimaciones.\n",
    "\n",
    "Es notable que las variables con errores estándar relativamente bajos (`Gr Liv Area`, `Lot Area`) están estimadas con gran precisión, mientras que aquellas con errores más altos (`Full Bath`, `Garage Cars`) presentan mayor incertidumbre en la estimación de su efecto sobre el precio de la vivienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7673920",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad73853",
   "metadata": {},
   "source": [
    "**Tabla 7.4.3.** Amplitud intervalos de confianza OLS vs. HC3 vs. Bootstrap.\n",
    "\n",
    "Alineados con los errores estándar ([Tabla 7.4.2](#tabla-742-se-ols-hc3-boot)), los intervalos calculados con OLS son consistentemente más estrechos que los obtenidos con HC3 o bootstrap, llegando a la misma conclusión de que el OLS inicial es menos robusto.\n",
    "\n",
    "## Takeaways\n",
    "- Los estimadores robustos mitigan la sensibilidad a outliers e incumplimientos de supuestos.\n",
    "- La regresión cuantílica describe efectos a lo largo de la distribución de la respuesta.\n",
    "- Se comparan *RMSE/MAE* y estabilidad de coeficientes versus OLS."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "source_map": [
   6,
   10,
   22,
   34,
   99,
   109,
   111,
   153,
   172,
   180,
   182,
   196,
   224,
   232,
   253,
   261,
   263,
   273,
   275
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}