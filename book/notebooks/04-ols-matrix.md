---
jupytext:
  formats: md:myst
  text_representation: {extension: .md, format_name: myst}
kernelspec: {name: python3, display_name: Python 3}
---
# CapÃ­tulo 4: FormulaciÃ³n matricial del modelo OLS

> **Overview**:
Se formula y ajusta un modelo OLS usando Ã¡lgebra matricial. Se presentan las ecuaciones clave (normal equations), verificando equivalencia con statsmodels. Presenta tabla de coeficientes en unidades monetarias para interpretaciÃ³n directa.

**Definir ruta de datos**

```{code-cell} ipython3
from pathlib import Path
import pandas as pd

# Definir ruta de datos relativa al capÃ­tulo (ejecutado desde book/notebooks/)
DATA_PATH = Path("../data/AmesHousing_sin_outliers.csv")
assert DATA_PATH.is_file(), f"No se encontrÃ³ '{DATA_PATH}'"
print("Usando CSV:", DATA_PATH.resolve())

# Lectura canÃ³nica a reutilizar en el capÃ­tulo
df = pd.read_csv(DATA_PATH)
df.shape
```
## DefiniciÃ³n del modelo

El modelo de regresiÃ³n lineal puede expresarse de forma matricial como:

$$
Y = X\beta + \varepsilon
$$

**EcuaciÃ³n 4.1.1.** RegresiÃ³n lineal.

La funciÃ³n de pÃ©rdida de mÃ­nimos cuadrados busca minimizar la suma de los errores al cuadrado:

$$
S(\beta) = (Y - X\beta)^\top (Y - X\beta)
$$

**EcuaciÃ³n 4.1.2.** FunciÃ³n de pÃ©rdida mÃ­nimos cuadrados.

Donde los estimadores estÃ¡n dados por:

$$
\hat{\beta} = (X^\top X)^{-1}X^\top Y
$$

**EcuaciÃ³n 4.1.3.** Estimadores de mÃ­nimos cuadrados.

```{code-cell} ipython3
import numpy as np
import pandas as pd
import statsmodels.api as sm

df = pd.read_csv(DATA_PATH)

vars_modelo = [
    'Overall Qual', 'Gr Liv Area', 'Garage Cars',
    'Total Bsmt SF', '1st Flr SF', 'Full Bath',
    'Year Built', 'Fireplaces', 'Lot Area'
]

y_log = df["SalePrice_log"].values
X = df[vars_modelo].values
X = np.column_stack([np.ones(X.shape[0]), X])
nombres_vars = ["Intercept"] + vars_modelo

XtX_inv = np.linalg.inv(X.T @ X)
beta_log = XtX_inv @ (X.T @ y_log)

modelo_log = sm.OLS(y_log, sm.add_constant(df[vars_modelo])).fit()

mean_price = np.exp(df["SalePrice_log"]).mean()
beta_usd = beta_log * mean_price
ols_usd = modelo_log.params.values * mean_price

tabla_comparacion = pd.DataFrame({
    "Variable": nombres_vars,
    "FormulaciÃ³n matricial": np.round(beta_usd, 2),
    "Statsmodels": np.round(ols_usd, 2)
})

display(tabla_comparacion)
```

**Tabla 4.1.1.** FormulaciÃ³n matricial vs. Statsmodels.

Se construye un modelo de regresiÃ³n lineal para predecir `SalePrice` a partir de nueve variables predictoras. 

Primero se calculan los coeficientes manualmente usando la formulaciÃ³n matricial de OLS, y luego se ajusta el mismo modelo con `statsmodels` para verificar los resultados. Se observan los mismos coeficientes.

Cada coeficiente indica cuÃ¡nto se espera que cambie el `SalePrice` por un incremento de una unidad en la variable correspondiente, manteniendo constantes las demÃ¡s variables. Por ejemplo, el coeficiente de `Overall Qual` es aproximadamente 17 686. Esto significa que, en promedio, por cada punto adicional en la calificaciÃ³n general de la casa, se espera que el precio de venta aumente unos 17 686 dÃ³lares, manteniendo constantes las otras variables del modelo.

> **Key takeaways**
>- La soluciÃ³n matricial reproduce exactamente la de librerÃ­as.
>- El condicionamiento de ğ‘‹â€²ğ‘‹ anticipa varianzas grandes si hay colinealidad.
>- Base teÃ³rica para pruebas e intervalos sobre ğ›½.
