---
jupytext:
  formats: md:myst
  text_representation: {extension: .md, format_name: myst}
kernelspec: {name: python3, display_name: Python 3}
---
# Cap√≠tulo 7: Remedios y m√©todos robustos


```{code-cell} ipython3
from pathlib import Path
DATA_PATH = Path("../data/AmesHousing_codificada.csv")  # relativo a book/notebooks/
assert DATA_PATH.is_file(), "No se encontr√≥ '../data/AmesHousing_codificada.csv'"
print("Usando CSV:", DATA_PATH.resolve())
```

---

## **Contexto**

Cuando el supuesto de **homocedasticidad** se viola (es decir, los residuos no tienen varianza constante), los estimadores OLS siguen siendo **insesgados**, pero sus **errores est√°ndar y valores p dejan de ser v√°lidos**.

Para corregirlo sin modificar los coeficientes, se usan las **correcciones de varianza robustas**, conocidas como **HC0, HC1, HC2 y HC3**.

---

## **Definici√≥n general**

La matriz de varianza-covarianza robusta se define como:

$$
\text{Var}(\hat{\beta}) = (X^\top X)^{-1} \left( X^\top \Omega X \right) (X^\top X)^{-1}
$$

donde \( \Omega \) es una matriz diagonal con los residuos al cuadrado corregidos seg√∫n el tipo de estimador HC.

---

## **Tipos de correcci√≥n (HC0‚ÄìHC3)**

| M√©todo |  Descripci√≥n |
|:-------|:-------------|
| **HC0** | White (1980). Asume grandes muestras. |
| **HC1** | Corrige el sesgo peque√±o de muestra. |
| **HC2** | Ajusta seg√∫n la influencia de cada observaci√≥n. |
| **HC3** | M√°s conservador; recomendado con outliers. |
## **Implementacion en Python**
```{code-cell} ipython3
import statsmodels.api as sm
import pandas as pd
# Ajustar modelo OLS normal
data_modelo_base = pd.read_csv(DATA_PATH)

data_modelo_base = data_modelo_base[['SalePrice','Overall Qual','Gr Liv Area','Garage Cars','Garage Area','Total Bsmt SF','1st Flr SF','Year Built','Year Remod/Add','Full Bath','Garage Yr Blt','TotRms AbvGrd','Fireplaces','Mas Vnr Area','BsmtFin SF 1']]
X = data_modelo_base[['Overall Qual','Gr Liv Area','Garage Cars','Garage Area','Year Built','Total Bsmt SF','Year Remod/Add','1st Flr SF','Full Bath','Garage Yr Blt','Fireplaces','TotRms AbvGrd']]
y = data_modelo_base[['SalePrice']]

X = sm.add_constant(X)

modelo_base = sm.OLS(y, X).fit()

# Aplicar correcciones HC0‚ÄìHC3
resultados_HC0 = modelo_base.get_robustcov_results(cov_type='HC0')
resultados_HC1 = modelo_base.get_robustcov_results(cov_type='HC1')
resultados_HC2 = modelo_base.get_robustcov_results(cov_type='HC2')
resultados_HC3 = modelo_base.get_robustcov_results(cov_type='HC3')

# Mostrar resumen comparativo
print("=== HC0 ===")
print(resultados_HC0.summary())
print("\n=== HC1 ===")
print(resultados_HC1.summary())
print("\n=== HC2 ===")
print(resultados_HC2.summary())
print("\n=== HC3 ===")
print(resultados_HC3.summary())
```
# **Resultados e interpretaci√≥n**

---

Los resultados del modelo OLS mostraron heterocedasticidad (p < 0.05 en las pruebas Breusch‚ÄìPagan y White).  
Para corregir los errores est√°ndar, se aplicaron las **correcciones robustas HC0, HC1, HC2 y HC3**, que ajustan la matriz de varianza sin modificar los coeficientes.


## **Resultados principales**

- Los **coeficientes estimados (\(\hat{\beta}\)) son id√©nticos** en todos los m√©todos ‚Üí OLS sigue siendo insesgado.  
- Cambian los **errores est√°ndar**, los **t-values** y, en menor medida, los **p-valores**.  
- Las diferencias entre HC0 y HC3 son m√≠nimas, lo cual indica que el modelo es **robusto** frente a la heterocedasticidad leve.

---

## **Interpretaci√≥n de los resultados**

| Variable | Significativa (p < 0.05)? | Comentario |
|:----------|:--------------------------|:------------|
| **OverallQual** | ‚úÖ S√≠ | Mayor calidad percibida ‚Üí mayor precio. |
| **GrLivArea** | ‚úÖ S√≠ | Cada m¬≤ adicional de √°rea habitable incrementa el valor. |
| **GarageCars** | ‚ö†Ô∏è No | El n√∫mero de autos del garaje no tiene efecto fuerte controlando por √°rea. |
| **GarageArea** | ‚úÖ S√≠ | Tama√±o del garaje s√≠ afecta el precio. |
| **YearBuilt** | ‚úÖ S√≠ | Casas m√°s nuevas valen m√°s. |
| **TotalBsmtSF** | ‚úÖ S√≠ | Mayor √°rea de s√≥tano aumenta el precio. |
| **YearRemod/Add** | ‚úÖ S√≠ | Renovaciones recientes incrementan valor. |
| **1stFlrSF** | ‚úÖ S√≠ | Contribuci√≥n positiva pero peque√±a. |
| **FullBath** | ‚úÖ S√≠ (negativa) | Posible correlaci√≥n con otras variables de tama√±o. |
| **GarageYrBlt** | ‚ùå No | No tiene efecto significativo. |
| **Fireplaces** | ‚úÖ S√≠ | Mayor n√∫mero de chimeneas aumenta valor. |
| **TotRmsAbvGrd** | ‚ùå No | Altamente correlacionada con √°rea habitable. |

---

## **Conclusi√≥n**

- El modelo **mantiene estabilidad estad√≠stica**: los signos y la significancia no cambian entre HC0 y HC3.  
- La **heterocedasticidad fue corregida** mediante errores est√°ndar robustos.  
- Los resultados m√°s confiables, en presencia de posibles outliers o alta varianza, son los obtenidos con **HC3**.  
- En adelante, para reportar los coeficientes y su significancia, debe usarse la versi√≥n **OLS (HC3)**.

---
# Modelos robustos RLM con Huber y Tukey

Aqu√≠ usamos `RLM` para ajustar modelos robustos que reducen el impacto de outliers:

- **Huber**: penaliza menos outliers moderados.  
- **Tukey**: limita fuertemente el efecto de outliers extremos.  

Se comparan los coeficientes y se examinan los pesos de cada observaci√≥n.

---

- Residuos peque√±os ‚Üí se tratan como en OLS (cuadr√°tico).  
- Residuos grandes ‚Üí penalizaci√≥n menor, reduciendo su efecto sobre los coeficientes.

---

## Funciones de p√©rdida comunes en RLM

| Funci√≥n | Comportamiento | Comentario |
|:--------|:--------------|:-----------|
| **HuberT** | Cuadr√°tica para residuos peque√±os, lineal para grandes | Protege contra outliers moderados manteniendo eficiencia |
| **TukeyBiweight** | Penalizaci√≥n progresiva hasta eliminar la influencia de residuos extremos | Muy robusto frente a outliers, pero menos eficiente si no hay outliers |

---

## Caracter√≠sticas

- Cada observaci√≥n recibe un **peso** seg√∫n su residuo: residuos grandes ‚Üí peso peque√±o.  
- Mantiene coeficientes estables ante **outliers extremos**.  
- Ideal para datasets con heterocedasticidad leve o outliers moderados/extremos.

---

## **Implementaci√≥n en Python**
```{code-cell} ipython3
# Modelos RLM
rlm_huber = sm.RLM(y, X, M=sm.robust.norms.HuberT()).fit()
rlm_tukey = sm.RLM(y, X, M=sm.robust.norms.TukeyBiweight()).fit()

# Comparaci√≥n de coeficientes
rlm_df = pd.DataFrame({
    'OLS': modelo_base.params,
    'RLM_Huber': rlm_huber.params,
    'RLM_Tukey': rlm_tukey.params
})

# Pesos de observaciones (para an√°lisis de outliers)
weights_df = pd.DataFrame({
    'Huber_weights': rlm_huber.weights,
    'Tukey_weights': rlm_tukey.weights
})

rlm_df, weights_df.head()
```
# **Bootstrap de coeficientes OLS**
Se realiza remuestreo bootstrap (B=1000 r√©plicas) para estimar la distribuci√≥n
de los coeficientes sin asumir normalidad, obteniendo errores est√°ndar y 
intervalos de confianza percentiles.
```{code-cell} ipython3
from sklearn.utils import resample
B = 1000
coef_boot = np.zeros((B, X.shape[1]))

for i in range(B):
    X_resample, y_resample = resample(X, y)
    model_bs = sm.OLS(y_resample, X_resample).fit()
    coef_boot[i, :] = model_bs.params

# Estad√≠sticas bootstrap
coef_mean = coef_boot.mean(axis=0)
coef_se = coef_boot.std(axis=0)
ic_lower = np.percentile(coef_boot, 2.5, axis=0)
ic_upper = np.percentile(coef_boot, 97.5, axis=0)

bootstrap_df = pd.DataFrame({
    'Coef_mean': coef_mean,
    'SE_bootstrap': coef_se,
    'IC_2.5%': ic_lower,
    'IC_97.5%': ic_upper
}, index=X.columns)

bootstrap_df.to_csv('boostrap_df.csv', sep=",", index = False)
bootstrap_df
```
# 3Ô∏è‚É£ Resultados principales: Bootstrap

- Los coeficientes promedio son casi id√©nticos a OLS.
- Los **errores est√°ndar se estiman directamente de la distribuci√≥n bootstrap**, capturando asimetr√≠as y posibles desviaciones de normalidad.
- Intervalos percentiles (2.5%-97.5%) permiten **IC robustos sin supuestos de normalidad**.
# Tabla comparativa final

Se comparan los resultados de los tres m√©todos principales:

- **Coeficientes estimados** (\(\hat{\beta}\))  
- **Errores est√°ndar**: OLS, HC3 y Bootstrap  
- **Amplitud de intervalos de confianza al 95%**

Esto permite identificar discrepancias significativas y evaluar la robustez del modelo.
```{code-cell} ipython3
# Ejemplo: coeficientes OLS y errores est√°ndar
coef_ols = modelo_base.params
se_ols = modelo_base.bse

# Errores est√°ndar robustos HC3
se_hc3 = resultados_HC3.bse

# Bootstrap: media y SE
coef_boot_mean = bootstrap_df['Coef_mean']
se_boot = bootstrap_df['SE_bootstrap']

# Intervalos de confianza OLS y HC3 (amplitud)
ic_ols = modelo_base.conf_int().iloc[:,1] - modelo_base.conf_int().iloc[:,0]

# Para HC3, conf_int() es ndarray, as√≠ que hacemos operaci√≥n directa
ic_hc3 = resultados_HC3.conf_int()[:,1] - resultados_HC3.conf_int()[:,0]

# Bootstrap: IC width
ic_boot = bootstrap_df['IC_97.5%'] - bootstrap_df['IC_2.5%']

# Crear DataFrame comparativo
comparative_df = pd.DataFrame({
    'Coef_OLS': coef_ols,
    'SE_OLS': se_ols,
    'SE_HC3': se_hc3,
    'Coef_Bootstrap': coef_boot_mean,
    'SE_Bootstrap': se_boot,
    'IC_width_OLS': ic_ols,
    'IC_width_HC3': ic_hc3,
    'IC_width_Bootstrap': ic_boot
})

comparative_df
```
```{code-cell} ipython3
import matplotlib.pyplot as plt
import numpy as np

# Calcular variaciones porcentuales respecto al modelo base (OLS)
var_SE_HC3 = 100 * (comparative_df['SE_HC3'] - comparative_df['SE_OLS']) / comparative_df['SE_OLS']
var_SE_Boot = 100 * (comparative_df['SE_Bootstrap'] - comparative_df['SE_OLS']) / comparative_df['SE_OLS']

var_IC_HC3 = 100 * (comparative_df['IC_width_HC3'] - comparative_df['IC_width_OLS']) / comparative_df['IC_width_OLS']
var_IC_Boot = 100 * (comparative_df['IC_width_Bootstrap'] - comparative_df['IC_width_OLS']) / comparative_df['IC_width_OLS']

# Variables
variables = comparative_df.index
x = np.arange(len(variables))
width = 0.3

# Funci√≥n para agregar etiquetas sobre barras
def add_labels(ax, bars):
    for bar in bars:
        height = bar.get_height()
        ax.annotate(f'{height:.1f}%',
                    xy=(bar.get_x() + bar.get_width() / 2, height),
                    xytext=(0, 3),  # desplazamiento vertical
                    textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)

# 1Ô∏è‚É£ Gr√°fico: Variaci√≥n porcentual de errores est√°ndar
fig, ax = plt.subplots(figsize=(12,5))
bars1 = ax.bar(x - width/2, var_SE_HC3, width, label='HC3')
bars2 = ax.bar(x + width/2, var_SE_Boot, width, label='Bootstrap')
ax.axhline(0, color='black', linewidth=0.8, linestyle='--')
ax.set_xticks(x)
ax.set_xticklabels(variables, rotation=45)
ax.set_ylabel('Variaci√≥n % vs OLS')
ax.set_title('Variaci√≥n porcentual de errores est√°ndar respecto a OLS')
ax.legend()
add_labels(ax, bars1)
add_labels(ax, bars2)
plt.tight_layout()
plt.show()

# 2Ô∏è‚É£ Gr√°fico: Variaci√≥n porcentual de amplitud de IC
fig, ax = plt.subplots(figsize=(12,5))
bars1 = ax.bar(x - width/2, var_IC_HC3, width, label='HC3')
bars2 = ax.bar(x + width/2, var_IC_Boot, width, label='Bootstrap')
ax.axhline(0, color='black', linewidth=0.8, linestyle='--')
ax.set_xticks(x)
ax.set_xticklabels(variables, rotation=45)
ax.set_ylabel('Variaci√≥n % vs OLS')
ax.set_title('Variaci√≥n porcentual de amplitud de IC 95% respecto a OLS')
ax.legend()
add_labels(ax, bars1)
add_labels(ax, bars2)
plt.tight_layout()
plt.show()
```
## Interpretaci√≥n

- **Coeficientes:** Todos los m√©todos muestran valores muy similares ‚Üí OLS sigue siendo insesgado.  
- **Errores est√°ndar:** HC3 y Bootstrap suelen ser m√°s conservadores que OLS cl√°sico.  
- **Intervalos de confianza:** Bootstrap e IC HC3 son m√°s amplios, reflejando mayor incertidumbre frente a outliers o heterocedasticidad.  

üí° **Conclusi√≥n:**  
- Diferencias entre m√©todos son peque√±as ‚Üí modelo robusto frente a heterocedasticidad leve y outliers moderados.  
- Para decisiones conservadoras (p-values o IC), se recomienda **HC3 o Bootstrap**.
